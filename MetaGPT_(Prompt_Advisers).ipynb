{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xtsQTW56K5XT",
        "IeafVcJnK_Ee",
        "NbEyUn7ULIS4",
        "mijUQmWmKnKb"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hariexcel/CodeRevAutoPR/blob/main/MetaGPT_(Prompt_Advisers).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.imgur.com/9aOj4of.png\" alt=\"picture\" width=\"25%\" />\n"
      ],
      "metadata": {
        "id": "biT3s4XrJNOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking to keep up with the latest and greatest in AI? Subscribe to our FREE newsletter for daily updates on the most recent news and trends: https://beyondbots.beehiiv.com/"
      ],
      "metadata": {
        "id": "F7vSUJieKkl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run this to install libraries and pull from GitHub"
      ],
      "metadata": {
        "id": "xtsQTW56K5XT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B2pwq1Vt85QQ",
        "outputId": "009c733e-53c1-4693-b445-8bbc92d1b665"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aiohttp==3.8.4\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting channels==4.0.0\n",
            "  Downloading channels-4.0.0-py3-none-any.whl (28 kB)\n",
            "Collecting duckduckgo_search==2.9.4\n",
            "  Downloading duckduckgo_search-2.9.4-py3-none-any.whl (31 kB)\n",
            "Collecting faiss_cpu==1.7.4\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fire==0.4.0\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langchain==0.0.231\n",
            "  Downloading langchain-0.0.231-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting loguru==0.6.0\n",
            "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting meilisearch==0.21.0\n",
            "  Downloading meilisearch-0.21.0-py3-none-any.whl (19 kB)\n",
            "Collecting numpy==1.24.3\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai==0.27.8\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.0.10)\n",
            "Collecting pandas==1.4.1\n",
            "  Downloading pandas-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic==1.10.7\n",
            "  Downloading pydantic-1.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytest==7.2.2 in /usr/local/lib/python3.10/dist-packages (7.2.2)\n",
            "Collecting python_docx==0.8.11\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyYAML==6.0\n",
            "  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools==65.6.3\n",
            "  Downloading setuptools-65.6.3-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity==8.2.2 in /usr/local/lib/python3.10/dist-packages (8.2.2)\n",
            "Collecting tiktoken==0.3.3\n",
            "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.0\n",
            "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anthropic==0.3.6\n",
            "  Downloading anthropic-0.3.6-py3-none-any.whl (793 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.6/793.6 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect==0.8.0\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Collecting typing_extensions==4.5.0\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4) (1.3.1)\n",
            "Collecting Django>=3.2 (from channels==4.0.0)\n",
            "  Downloading Django-4.2.4-py3-none-any.whl (8.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asgiref<4,>=3.5.0 (from channels==4.0.0)\n",
            "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from duckduckgo_search==2.9.4) (8.1.6)\n",
            "Collecting diskcache>=5.6.1 (from duckduckgo_search==2.9.4)\n",
            "  Downloading diskcache-5.6.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.29.0 (from duckduckgo_search==2.9.4)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire==0.4.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire==0.4.0) (2.3.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (2.0.19)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.231)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langchainplus-sdk<0.0.21,>=0.0.20 (from langchain==0.0.231)\n",
            "  Downloading langchainplus_sdk-0.0.20-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (2.8.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.231)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting camel-converter[pydantic] (from meilisearch==0.21.0)\n",
            "  Downloading camel_converter-3.0.2-py3-none-any.whl (5.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.4.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.4.1) (2022.7.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest==7.2.2) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest==7.2.2) (23.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest==7.2.2) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest==7.2.2) (1.1.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest==7.2.2) (2.0.1)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python_docx==0.8.11) (4.9.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3) (2022.10.31)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic==0.3.6) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic==0.3.6) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from anthropic==0.3.6)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers>=0.13.0 (from anthropic==0.3.6)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy-extensions>=0.3.0 (from typing-inspect==0.8.0)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->anthropic==0.3.6) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->anthropic==0.3.6) (1.3.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from Django>=3.2->channels==4.0.0) (0.4.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic==0.3.6) (2023.7.22)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx<1,>=0.23.0->anthropic==0.3.6)\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.29.0->duckduckgo_search==2.9.4) (1.26.16)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.231) (2.0.2)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->anthropic==0.3.6)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire, python_docx\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115926 sha256=d861449379f0e4be163d933e05d96364a579d43f45be596ba3238238816c0e23\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/9a/dd/2818b1b023daf077ec3e625c47ae446aca587a5abe48e05212\n",
            "  Building wheel for python_docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python_docx: filename=python_docx-0.8.11-py3-none-any.whl size=184489 sha256=8dfa3b14a97bf66893581f33591d74f189e805982c00b79a0cd6e08c53f9d66b\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "Successfully built fire python_docx\n",
            "Installing collected packages: tokenizers, faiss_cpu, typing_extensions, tqdm, setuptools, requests, PyYAML, python_docx, numpy, mypy-extensions, marshmallow, loguru, h11, fire, diskcache, camel-converter, typing-inspect, tiktoken, pydantic, pandas, httpcore, duckduckgo_search, asgiref, aiohttp, openapi-schema-pydantic, openai, langchainplus-sdk, httpx, Django, dataclasses-json, meilisearch, langchain, channels, anthropic\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.1\n",
            "    Uninstalling PyYAML-6.0.1:\n",
            "      Successfully uninstalled PyYAML-6.0.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.12\n",
            "    Uninstalling pydantic-1.10.12:\n",
            "      Successfully uninstalled pydantic-1.10.12\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.8.5\n",
            "    Uninstalling aiohttp-3.8.5:\n",
            "      Successfully uninstalled aiohttp-3.8.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 1.4.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.3 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Django-4.2.4 PyYAML-6.0 aiohttp-3.8.4 anthropic-0.3.6 asgiref-3.7.2 camel-converter-3.0.2 channels-4.0.0 dataclasses-json-0.5.14 diskcache-5.6.1 duckduckgo_search-2.9.4 faiss_cpu-1.7.4 fire-0.4.0 h11-0.14.0 httpcore-0.17.3 httpx-0.24.1 langchain-0.0.231 langchainplus-sdk-0.0.20 loguru-0.6.0 marshmallow-3.20.1 meilisearch-0.21.0 mypy-extensions-1.0.0 numpy-1.24.3 openai-0.27.8 openapi-schema-pydantic-1.2.4 pandas-1.4.1 pydantic-1.10.7 python_docx-0.8.11 requests-2.31.0 setuptools-65.6.3 tiktoken-0.3.3 tokenizers-0.13.3 tqdm-4.64.0 typing-inspect-0.8.0 typing_extensions-4.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "numpy",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'metagpt'...\n",
            "remote: Enumerating objects: 1661, done.\u001b[K\n",
            "remote: Counting objects: 100% (597/597), done.\u001b[K\n",
            "remote: Compressing objects: 100% (179/179), done.\u001b[K\n",
            "remote: Total 1661 (delta 471), reused 425 (delta 418), pack-reused 1064\u001b[K\n",
            "Receiving objects: 100% (1661/1661), 3.73 MiB | 18.91 MiB/s, done.\n",
            "Resolving deltas: 100% (1094/1094), done.\n",
            "/content/metagpt\n",
            "Setup is complete. You can now run your software!\n"
          ]
        }
      ],
      "source": [
        "# Install the required Python packages\n",
        "!pip install aiohttp==3.8.4 channels==4.0.0 duckduckgo_search==2.9.4 \\\n",
        "    faiss_cpu==1.7.4 fire==0.4.0 langchain==0.0.231 loguru==0.6.0 \\\n",
        "    meilisearch==0.21.0 numpy==1.24.3 openai==0.27.8 openpyxl \\\n",
        "    pandas==1.4.1 pydantic==1.10.7 pytest==7.2.2 python_docx==0.8.11 \\\n",
        "    PyYAML==6.0 setuptools==65.6.3 tenacity==8.2.2 tiktoken==0.3.3 \\\n",
        "    tqdm==4.64.0 anthropic==0.3.6 typing-inspect==0.8.0 typing_extensions==4.5.0\n",
        "\n",
        "# Clone the repository\n",
        "!git clone https://github.com/geekan/metagpt  # Adjust the URL to the actual repository if it's different.\n",
        "\n",
        "# Change directory to cloned repository\n",
        "%cd metagpt\n",
        "\n",
        "# Since npm is not supported in Colab, I'm omitting the attempt to install mermaid-cli.\n",
        "\n",
        "print(\"Setup is complete. You can now run your software!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enter Your OpenAI Key Below"
      ],
      "metadata": {
        "id": "IeafVcJnK_Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = ''"
      ],
      "metadata": {
        "id": "illzcKb2_E2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run MetaGPT"
      ],
      "metadata": {
        "id": "NbEyUn7ULIS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/metagpt/startup.py \"Build a tool for recruiters to leverage AI in their day-to-day operations.\" --investment 10000.0 --n_round 5 --code_review False --run_tests False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miZ1U7ct9jI4",
        "outputId": "fbcad312-eef5-48b8-98bf-3687e56accff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2023-08-08 00:49:33.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.config\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mConfig loading done.\u001b[0m\n",
            "\u001b[32m2023-08-08 00:49:36.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.software_company\u001b[0m:\u001b[36minvest\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mInvestment: $10000.0.\u001b[0m\n",
            "\u001b[32m2023-08-08 00:49:36.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.roles.role\u001b[0m:\u001b[36m_act\u001b[0m:\u001b[36m167\u001b[0m - \u001b[1mAlice(Product Manager): ready to WritePRD\u001b[0m\n",
            "## Original Requirements\n",
            "The boss wants us to build a tool for recruiters to leverage AI in their day-to-day operations.\n",
            "\n",
            "## Product Goals\n",
            "```python\n",
            "[\n",
            "    \"Create a tool that integrates AI to streamline the recruitment process\",\n",
            "    \"Improve efficiency and accuracy in candidate selection\",\n",
            "    \"Provide insightful data analytics to aid in decision-making\"\n",
            "]\n",
            "```\n",
            "\n",
            "## User Stories\n",
            "```python\n",
            "[\n",
            "    \"As a recruiter, I want to easily sift through a large number of applications, so I can shortlist candidates more efficiently\",\n",
            "    \"As a recruiter, I want to leverage AI to identify the best-fit candidates, so I can reduce the time spent on manual screening\",\n",
            "    \"As a recruiter, I want to have a dashboard that displays insightful analytics, so I can make data-driven decisions\",\n",
            "    \"As a recruiter, I want to track the progress of each candidate, so I can manage the recruitment pipeline effectively\",\n",
            "    \"As a recruiter, I want to automate repetitive tasks, so I can focus on more strategic aspects of recruitment\"\n",
            "]\n",
            "```\n",
            "\n",
            "## Competitive Analysis\n",
            "```python\n",
            "[\n",
            "    \"LinkedIn Recruiter: Offers a comprehensive suite of tools but lacks advanced AI capabilities\",\n",
            "    \"Zoho Recruit: Provides AI-powered candidate matching but lacks robust data analytics\",\n",
            "    \"Workable: Features a strong AI matching system but the user interface can be improved\",\n",
            "    \"Jobvite: Offers a good balance of AI and analytics but can be expensive for small businesses\",\n",
            "    \"Greenhouse: Known for its user-friendly interface but lacks advanced AI features\",\n",
            "    \"Lever: Provides robust analytics but the AI capabilities are not as strong\",\n",
            "    \"Breezy HR: Offers a good balance of AI and analytics but the user interface can be improved\"\n",
            "]\n",
            "```\n",
            "\n",
            "## Competitive Quadrant Chart\n",
            "```mermaid\n",
            "quadrantChart\n",
            "    title AI Capabilities and Data Analytics of Competitors\n",
            "    x-axis Low AI Capabilities --> High AI Capabilities\n",
            "    y-axis Low Data Analytics --> High Data Analytics\n",
            "    quadrant-1 We should expand\n",
            "    quadrant-2 Need to promote\n",
            "    quadrant-3 Re-evaluate\n",
            "    quadrant-4 May be improved\n",
            "    \"LinkedIn Recruiter\": [0.4, 0.6]\n",
            "    \"Zoho Recruit\": [0.7, 0.4]\n",
            "    \"Workable\": [0.6, 0.5]\n",
            "    \"Jobvite\": [0.5, 0.5]\n",
            "    \"Greenhouse\": [0.4, 0.7]\n",
            "    \"Lever\": [0.5, 0.6]\n",
            "    \"Breezy HR\": [0.6, 0.4]\n",
            "    \"Our Target Product\": [0.8, 0.8]\n",
            "```\n",
            "\n",
            "## Requirement Analysis\n",
            "The product should be a web-based tool that integrates AI to automate and streamline the recruitment process. It should offer features such as AI-powered candidate matching, a dashboard for data analytics, candidate tracking, and task automation.\n",
            "\n",
            "## Requirement Pool\n",
            "```python\n",
            "[\n",
            "    (\"AI-powered candidate matching\", \"P0\"),\n",
            "    (\"Data analytics dashboard\", \"P0\"),\n",
            "    (\"Candidate tracking system\", \"P1\"),\n",
            "    (\"Task automation\", \"P1\"),\n",
            "    (\"User-friendly interface\", \"P2\")\n",
            "]\n",
            "```\n",
            "\n",
            "## UI Design draft\n",
            "The main elements of the UI should include a navigation bar, a dashboard, a candidate list, and a task list. The dashboard should display key analytics in a visually appealing manner using charts and graphs. The candidate list should allow for easy sorting and filtering. The task list should provide a clear overview of pending tasks. The overall design should be clean and minimalist, with a focus on usability.\n",
            "\n",
            "## Anything UNCLEAR\n",
            "There are no unclear points.\n",
            "\u001b[32m2023-08-08 00:50:28.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.roles.role\u001b[0m:\u001b[36m_act\u001b[0m:\u001b[36m167\u001b[0m - \u001b[1mBob(Architect): ready to WriteDesign\u001b[0m\n",
            "## Implementation approach\n",
            "We will use Flask as the web framework for building the recruitment tool. Flask is lightweight and flexible, making it a good choice for our project. For the AI-powered candidate matching, we will use the Natural Language Processing (NLP) library, spaCy, to analyze and compare candidate profiles. For the data analytics dashboard, we will use Plotly, a graphing library for making interactive, publication-quality graphs. For the candidate tracking system, we will use SQLite as a lightweight disk-based database that doesn't require a separate server process. For task automation, we will use Celery, a simple, flexible, and reliable distributed system to process vast amounts of messages. The user interface will be built using Bootstrap, a free and open-source CSS framework.\n",
            "\n",
            "## Python package name\n",
            "```python\n",
            "\"ai_recruiter\"\n",
            "```\n",
            "\n",
            "## File list\n",
            "```python\n",
            "[\n",
            "    \"main.py\",\n",
            "    \"candidate_matching.py\",\n",
            "    \"dashboard.py\",\n",
            "    \"candidate_tracking.py\",\n",
            "    \"task_automation.py\",\n",
            "    \"templates/index.html\",\n",
            "    \"static/css/main.css\",\n",
            "    \"requirements.txt\"\n",
            "]\n",
            "```\n",
            "\n",
            "## Data structures and interface definitions\n",
            "```mermaid\n",
            "classDiagram\n",
            "    class Main{\n",
            "        +Flask app\n",
            "        +run()\n",
            "    }\n",
            "    class CandidateMatching{\n",
            "        +Spacy nlp\n",
            "        +match(candidate: str, job_description: str): float\n",
            "    }\n",
            "    class Dashboard{\n",
            "        +Plotly plot\n",
            "        +generate_dashboard(data: dict): str\n",
            "    }\n",
            "    class CandidateTracking{\n",
            "        +SQLite3 db\n",
            "        +add_candidate(candidate: dict)\n",
            "        +update_candidate(candidate: dict)\n",
            "        +delete_candidate(candidate_id: str)\n",
            "        +get_candidate(candidate_id: str): dict\n",
            "    }\n",
            "    class TaskAutomation{\n",
            "        +Celery task\n",
            "        +automate_task(task: str)\n",
            "    }\n",
            "    Main -- CandidateMatching\n",
            "    Main -- Dashboard\n",
            "    Main -- CandidateTracking\n",
            "    Main -- TaskAutomation\n",
            "```\n",
            "\n",
            "## Program call flow\n",
            "```mermaid\n",
            "sequenceDiagram\n",
            "    participant M as Main\n",
            "    participant CM as CandidateMatching\n",
            "    participant D as Dashboard\n",
            "    participant CT as CandidateTracking\n",
            "    participant TA as TaskAutomation\n",
            "    M->>CM: match(candidate, job_description)\n",
            "    CM-->>M: match_score\n",
            "    M->>D: generate_dashboard(data)\n",
            "    D-->>M: dashboard_html\n",
            "    M->>CT: add_candidate(candidate)\n",
            "    CT-->>M: candidate_id\n",
            "    M->>TA: automate_task(task)\n",
            "    TA-->>M: task_status\n",
            "```\n",
            "\n",
            "## Anything UNCLEAR\n",
            "The requirement is clear to me.\n",
            "no mermaid\n",
            "\u001b[32m2023-08-08 00:51:12.260\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mmetagpt.utils.mermaid\u001b[0m:\u001b[36mmermaid_to_file\u001b[0m:\u001b[36m31\u001b[0m - \u001b[33m\u001b[1mRUN `npm install -g @mermaid-js/mermaid-cli` to install mmdc\u001b[0m\n",
            "\u001b[32m2023-08-08 00:51:12.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.actions.design_api\u001b[0m:\u001b[36m_save_prd\u001b[0m:\u001b[36m110\u001b[0m - \u001b[1mSaving PRD to /content/metagpt/workspace/ai_recruiter/docs/prd.md\u001b[0m\n",
            "no mermaid\n",
            "\u001b[32m2023-08-08 00:51:12.262\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mmetagpt.utils.mermaid\u001b[0m:\u001b[36mmermaid_to_file\u001b[0m:\u001b[36m31\u001b[0m - \u001b[33m\u001b[1mRUN `npm install -g @mermaid-js/mermaid-cli` to install mmdc\u001b[0m\n",
            "no mermaid\n",
            "\u001b[32m2023-08-08 00:51:12.262\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mmetagpt.utils.mermaid\u001b[0m:\u001b[36mmermaid_to_file\u001b[0m:\u001b[36m31\u001b[0m - \u001b[33m\u001b[1mRUN `npm install -g @mermaid-js/mermaid-cli` to install mmdc\u001b[0m\n",
            "\u001b[32m2023-08-08 00:51:12.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.actions.design_api\u001b[0m:\u001b[36m_save_system_design\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mSaving System Designs to /content/metagpt/workspace/ai_recruiter/docs/system_design.md\u001b[0m\n",
            "\u001b[32m2023-08-08 00:51:12.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.roles.role\u001b[0m:\u001b[36m_act\u001b[0m:\u001b[36m167\u001b[0m - \u001b[1mEve(Project Manager): ready to WriteTasks\u001b[0m\n",
            "## Required Python third-party packages\n",
            "```python\n",
            "\"\"\"\n",
            "flask==1.1.2\n",
            "spacy==3.1.3\n",
            "plotly==5.3.1\n",
            "sqlite3==2.6.0\n",
            "celery==5.1.2\n",
            "bootstrap==5.1.3\n",
            "\"\"\"\n",
            "```\n",
            "\n",
            "## Required Other language third-party packages\n",
            "```python\n",
            "\"\"\"\n",
            "No third-party packages required in other languages.\n",
            "\"\"\"\n",
            "```\n",
            "\n",
            "## Full API spec\n",
            "```python\n",
            "\"\"\"\n",
            "openapi: 3.0.0\n",
            "info:\n",
            "  version: 1.0.0\n",
            "  title: AI Recruiter\n",
            "paths:\n",
            "  /match:\n",
            "    post:\n",
            "      summary: Match a candidate with a job description\n",
            "      requestBody:\n",
            "        content:\n",
            "          application/json:\n",
            "            schema:\n",
            "              type: object\n",
            "              properties:\n",
            "                candidate:\n",
            "                  type: string\n",
            "                job_description:\n",
            "                  type: string\n",
            "      responses:\n",
            "        '200':\n",
            "          description: A match score\n",
            "  /dashboard:\n",
            "    get:\n",
            "      summary: Get the data analytics dashboard\n",
            "      responses:\n",
            "        '200':\n",
            "          description: An HTML string of the dashboard\n",
            "  /candidate:\n",
            "    post:\n",
            "      summary: Add a candidate\n",
            "      requestBody:\n",
            "        content:\n",
            "          application/json:\n",
            "            schema:\n",
            "              type: object\n",
            "              properties:\n",
            "                candidate:\n",
            "                  type: object\n",
            "      responses:\n",
            "        '200':\n",
            "          description: The ID of the added candidate\n",
            "    put:\n",
            "      summary: Update a candidate\n",
            "      requestBody:\n",
            "        content:\n",
            "          application/json:\n",
            "            schema:\n",
            "              type: object\n",
            "              properties:\n",
            "                candidate:\n",
            "                  type: object\n",
            "      responses:\n",
            "        '200':\n",
            "          description: The ID of the updated candidate\n",
            "    delete:\n",
            "      summary: Delete a candidate\n",
            "      parameters:\n",
            "        - name: candidate_id\n",
            "          in: query\n",
            "          required: true\n",
            "          schema:\n",
            "            type: string\n",
            "      responses:\n",
            "        '200':\n",
            "          description: The ID of the deleted candidate\n",
            "  /task:\n",
            "    post:\n",
            "      summary: Automate a task\n",
            "      requestBody:\n",
            "        content:\n",
            "          application/json:\n",
            "            schema:\n",
            "              type: object\n",
            "              properties:\n",
            "                task:\n",
            "                  type: string\n",
            "      responses:\n",
            "        '200':\n",
            "          description: The status of the task\n",
            "\"\"\"\n",
            "```\n",
            "\n",
            "## Logic Analysis\n",
            "```python\n",
            "[\n",
            "    (\"main.py\", \"Contains the Flask app and the main entry of the program. It calls the other modules.\"),\n",
            "    (\"candidate_matching.py\", \"Implements the match function using spaCy. It is called by main.py.\"),\n",
            "    (\"dashboard.py\", \"Generates the data analytics dashboard using Plotly. It is called by main.py.\"),\n",
            "    (\"candidate_tracking.py\", \"Manages the candidate data using SQLite3. It is called by main.py.\"),\n",
            "    (\"task_automation.py\", \"Automates tasks using Celery. It is called by main.py.\"),\n",
            "]\n",
            "```\n",
            "\n",
            "## Task list\n",
            "```python\n",
            "[\n",
            "    \"main.py\",\n",
            "    \"candidate_matching.py\",\n",
            "    \"dashboard.py\",\n",
            "    \"candidate_tracking.py\",\n",
            "    \"task_automation.py\",\n",
            "]\n",
            "```\n",
            "\n",
            "## Shared Knowledge\n",
            "```python\n",
            "\"\"\"\n",
            "The 'main.py' file contains the main entry of the program and calls the other modules. \n",
            "The 'candidate_matching.py' file implements the match function using spaCy. \n",
            "The 'dashboard.py' file generates the data analytics dashboard using Plotly. \n",
            "The 'candidate_tracking.py' file manages the candidate data using SQLite3. \n",
            "The 'task_automation.py' file automates tasks using Celery.\n",
            "\"\"\"\n",
            "```\n",
            "\n",
            "## Anything UNCLEAR\n",
            "We need to clarify how to start the Flask app and how to initialize the third-party libraries.\n",
            "\u001b[32m2023-08-08 00:52:14.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.actions.write_code\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mWriting main.py..\u001b[0m\n",
            "## Code: main.py\n",
            "```python\n",
            "## main.py\n",
            "from flask import Flask, request, jsonify\n",
            "from candidate_matching import CandidateMatching\n",
            "from dashboard import Dashboard\n",
            "from candidate_tracking import CandidateTracking\n",
            "from task_automation import TaskAutomation\n",
            "\n",
            "app = Flask(__name__)\n",
            "candidate_matching = CandidateMatching()\n",
            "dashboard = Dashboard()\n",
            "candidate_tracking = CandidateTracking()\n",
            "task_automation = TaskAutomation()\n",
            "\n",
            "@app.route('/match', methods=['POST'])\n",
            "def match():\n",
            "    candidate = request.json['candidate']\n",
            "    job_description = request.json['job_description']\n",
            "    match_score = candidate_matching.match(candidate, job_description)\n",
            "    return jsonify({'match_score': match_score})\n",
            "\n",
            "@app.route('/dashboard', methods=['GET'])\n",
            "def generate_dashboard():\n",
            "    data = {}  # Fetch data from database or other sources\n",
            "    dashboard_html = dashboard.generate_dashboard(data)\n",
            "    return jsonify({'dashboard_html': dashboard_html})\n",
            "\n",
            "@app.route('/candidate', methods=['POST', 'PUT', 'DELETE'])\n",
            "def manage_candidate():\n",
            "    if request.method == 'POST':\n",
            "        candidate = request.json['candidate']\n",
            "        candidate_id = candidate_tracking.add_candidate(candidate)\n",
            "        return jsonify({'candidate_id': candidate_id})\n",
            "    elif request.method == 'PUT':\n",
            "        candidate = request.json['candidate']\n",
            "        candidate_id = candidate_tracking.update_candidate(candidate)\n",
            "        return jsonify({'candidate_id': candidate_id})\n",
            "    elif request.method == 'DELETE':\n",
            "        candidate_id = request.args.get('candidate_id')\n",
            "        candidate_id = candidate_tracking.delete_candidate(candidate_id)\n",
            "        return jsonify({'candidate_id': candidate_id})\n",
            "\n",
            "@app.route('/task', methods=['POST'])\n",
            "def automate_task():\n",
            "    task = request.json['task']\n",
            "    task_status = task_automation.automate_task(task)\n",
            "    return jsonify({'task_status': task_status})\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    app.run(debug=True)\n",
            "```\n",
            "Please note that this is a basic implementation. The actual implementation may require more complex handling, such as error checking, data validation, and more sophisticated routing. Also, the `data` for generating the dashboard is currently an empty dictionary. In a real-world application, this data would likely come from a database or other data source.\n",
            "\u001b[32m2023-08-08 00:52:47.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.actions.write_code\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mWriting candidate_matching.py..\u001b[0m\n",
            "## Code: candidate_matching.py\n",
            "```python\n",
            "import spacy\n",
            "\n",
            "class CandidateMatching:\n",
            "    def __init__(self):\n",
            "        self.nlp = spacy.load('en_core_web_sm')\n",
            "\n",
            "    def match(self, candidate: str, job_description: str) -> float:\n",
            "        candidate_doc = self.nlp(candidate)\n",
            "        job_description_doc = self.nlp(job_description)\n",
            "        match_score = candidate_doc.similarity(job_description_doc)\n",
            "        return match_score\n",
            "```\n",
            "-----\n",
            "This code defines a class `CandidateMatching` that uses the spaCy library to perform Natural Language Processing (NLP) on the input strings. The `match` function takes in two strings, `candidate` and `job_description`, converts them into spaCy `Doc` objects, and then calculates the similarity between them. The similarity score is a float between 0 and 1, where 1 means the two documents are identical.\n",
            "\u001b[32m2023-08-08 00:52:59.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.actions.write_code\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mWriting dashboard.py..\u001b[0m\n",
            "## Code: dashboard.py\n",
            "```python\n",
            "import plotly.graph_objects as go\n",
            "\n",
            "class Dashboard:\n",
            "    def __init__(self):\n",
            "        self.plot = go.Figure()\n",
            "\n",
            "    def generate_dashboard(self, data: dict) -> str:\n",
            "        # Generate dashboard based on the data\n",
            "        # For simplicity, let's assume the data is a dictionary with keys as labels and values as numbers\n",
            "        labels = list(data.keys())\n",
            "        values = list(data.values())\n",
            "\n",
            "        # Create a pie chart\n",
            "        self.plot.add_trace(go.Pie(labels=labels, values=values))\n",
            "\n",
            "        # Convert the plot to HTML string\n",
            "        dashboard_html = self.plot.to_html()\n",
            "\n",
            "        return dashboard_html\n",
            "```\n",
            "This code defines a class `Dashboard` which uses Plotly to generate a dashboard in the form of a pie chart. The `generate_dashboard` function takes a dictionary as input, where keys are labels and values are numbers. It creates a pie chart based on this data and returns the plot as an HTML string.\n",
            "\u001b[32m2023-08-08 00:53:23.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.actions.write_code\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mWriting candidate_tracking.py..\u001b[0m\n",
            "## Code: candidate_tracking.py\n",
            "```python\n",
            "import sqlite3\n",
            "from typing import Dict\n",
            "\n",
            "class CandidateTracking:\n",
            "    def __init__(self, db_path: str = 'candidates.db'):\n",
            "        self.db = sqlite3.connect(db_path)\n",
            "        self.cursor = self.db.cursor()\n",
            "        self.cursor.execute(\"\"\"\n",
            "            CREATE TABLE IF NOT EXISTS candidates(\n",
            "                id INTEGER PRIMARY KEY,\n",
            "                name TEXT,\n",
            "                skills TEXT,\n",
            "                experience TEXT,\n",
            "                match_score FLOAT\n",
            "            )\n",
            "        \"\"\")\n",
            "\n",
            "    def add_candidate(self, candidate: Dict[str, str]) -> int:\n",
            "        self.cursor.execute(\"\"\"\n",
            "            INSERT INTO candidates(name, skills, experience, match_score)\n",
            "            VALUES (:name, :skills, :experience, :match_score)\n",
            "        \"\"\", candidate)\n",
            "        self.db.commit()\n",
            "        return self.cursor.lastrowid\n",
            "\n",
            "    def update_candidate(self, candidate: Dict[str, str]) -> int:\n",
            "        self.cursor.execute(\"\"\"\n",
            "            UPDATE candidates\n",
            "            SET name = :name, skills = :skills, experience = :experience, match_score = :match_score\n",
            "            WHERE id = :id\n",
            "        \"\"\", candidate)\n",
            "        self.db.commit()\n",
            "        return candidate['id']\n",
            "\n",
            "    def delete_candidate(self, candidate_id: int) -> int:\n",
            "        self.cursor.execute(\"\"\"\n",
            "            DELETE FROM candidates\n",
            "            WHERE id = ?\n",
            "        \"\"\", (candidate_id,))\n",
            "        self.db.commit()\n",
            "        return candidate_id\n",
            "\n",
            "    def get_candidate(self, candidate_id: int) -> Dict[str, str]:\n",
            "        self.cursor.execute(\"\"\"\n",
            "            SELECT * FROM candidates\n",
            "            WHERE id = ?\n",
            "        \"\"\", (candidate_id,))\n",
            "        candidate = self.cursor.fetchone()\n",
            "        return dict(candidate) if candidate else None\n",
            "```\n",
            "\n",
            "\u001b[32m2023-08-08 00:53:51.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.actions.write_code\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mWriting task_automation.py..\u001b[0m\n",
            "## Code: task_automation.py\n",
            "```python\n",
            "from celery import Celery\n",
            "\n",
            "class TaskAutomation:\n",
            "    def __init__(self, broker_url: str = 'pyamqp://guest@localhost//'):\n",
            "        self.task = Celery('tasks', broker=broker_url)\n",
            "\n",
            "    @self.task.task\n",
            "    def automate_task(self, task: str) -> str:\n",
            "        # Implement the task automation logic here\n",
            "        # For simplicity, let's just return the task name\n",
            "        return task\n",
            "```\n",
            "-----\n",
            "\u001b[32m2023-08-08 00:54:05.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.roles.engineer\u001b[0m:\u001b[36m_act_sp\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1mDone /content/metagpt/workspace/ai_recruiter/ai_recruiter generating.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Display the Results More Cleanly"
      ],
      "metadata": {
        "id": "mijUQmWmKnKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def display_md_files(path):\n",
        "    # Loop through folders\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "            if file.endswith('.md'):\n",
        "                file_path = os.path.join(root, file)\n",
        "\n",
        "                # Display the name of the file\n",
        "                print(f\"Content of {file_path}:\\n\")\n",
        "\n",
        "                with open(file_path, 'r') as f:\n",
        "                    content = f.read()\n",
        "                    # Display content in markdown format\n",
        "                    display(Markdown(content))\n",
        "                    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Start the function with the main path\n",
        "display_md_files(\"/content/metagpt/workspace\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XoAMVbp2DB72",
        "outputId": "8171d839-ed5e-46f3-9658-f2b923b177a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content of /content/metagpt/workspace/ai_recruiter/docs/api_spec_and_tasks.md:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Required Python third-party packages\n```python\n\"\"\"\nflask==1.1.2\nspacy==3.1.3\nplotly==5.3.1\nsqlite3==2.6.0\ncelery==5.1.2\nbootstrap==5.1.3\n\"\"\"\n```\n\n## Required Other language third-party packages\n```python\n\"\"\"\nNo third-party packages required in other languages.\n\"\"\"\n```\n\n## Full API spec\n```python\n\"\"\"\nopenapi: 3.0.0\ninfo:\n  version: 1.0.0\n  title: AI Recruiter\npaths:\n  /match:\n    post:\n      summary: Match a candidate with a job description\n      requestBody:\n        content:\n          application/json:\n            schema:\n              type: object\n              properties:\n                candidate:\n                  type: string\n                job_description:\n                  type: string\n      responses:\n        '200':\n          description: A match score\n  /dashboard:\n    get:\n      summary: Get the data analytics dashboard\n      responses:\n        '200':\n          description: An HTML string of the dashboard\n  /candidate:\n    post:\n      summary: Add a candidate\n      requestBody:\n        content:\n          application/json:\n            schema:\n              type: object\n              properties:\n                candidate:\n                  type: object\n      responses:\n        '200':\n          description: The ID of the added candidate\n    put:\n      summary: Update a candidate\n      requestBody:\n        content:\n          application/json:\n            schema:\n              type: object\n              properties:\n                candidate:\n                  type: object\n      responses:\n        '200':\n          description: The ID of the updated candidate\n    delete:\n      summary: Delete a candidate\n      parameters:\n        - name: candidate_id\n          in: query\n          required: true\n          schema:\n            type: string\n      responses:\n        '200':\n          description: The ID of the deleted candidate\n  /task:\n    post:\n      summary: Automate a task\n      requestBody:\n        content:\n          application/json:\n            schema:\n              type: object\n              properties:\n                task:\n                  type: string\n      responses:\n        '200':\n          description: The status of the task\n\"\"\"\n```\n\n## Logic Analysis\n```python\n[\n    (\"main.py\", \"Contains the Flask app and the main entry of the program. It calls the other modules.\"),\n    (\"candidate_matching.py\", \"Implements the match function using spaCy. It is called by main.py.\"),\n    (\"dashboard.py\", \"Generates the data analytics dashboard using Plotly. It is called by main.py.\"),\n    (\"candidate_tracking.py\", \"Manages the candidate data using SQLite3. It is called by main.py.\"),\n    (\"task_automation.py\", \"Automates tasks using Celery. It is called by main.py.\"),\n]\n```\n\n## Task list\n```python\n[\n    \"main.py\",\n    \"candidate_matching.py\",\n    \"dashboard.py\",\n    \"candidate_tracking.py\",\n    \"task_automation.py\",\n]\n```\n\n## Shared Knowledge\n```python\n\"\"\"\nThe 'main.py' file contains the main entry of the program and calls the other modules. \nThe 'candidate_matching.py' file implements the match function using spaCy. \nThe 'dashboard.py' file generates the data analytics dashboard using Plotly. \nThe 'candidate_tracking.py' file manages the candidate data using SQLite3. \nThe 'task_automation.py' file automates tasks using Celery.\n\"\"\"\n```\n\n## Anything UNCLEAR\nWe need to clarify how to start the Flask app and how to initialize the third-party libraries."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "\n",
            "Content of /content/metagpt/workspace/ai_recruiter/docs/system_design.md:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Implementation approach\nWe will use Flask as the web framework for building the recruitment tool. Flask is lightweight and flexible, making it a good choice for our project. For the AI-powered candidate matching, we will use the Natural Language Processing (NLP) library, spaCy, to analyze and compare candidate profiles. For the data analytics dashboard, we will use Plotly, a graphing library for making interactive, publication-quality graphs. For the candidate tracking system, we will use SQLite as a lightweight disk-based database that doesn't require a separate server process. For task automation, we will use Celery, a simple, flexible, and reliable distributed system to process vast amounts of messages. The user interface will be built using Bootstrap, a free and open-source CSS framework.\n\n## Python package name\n```python\n\"ai_recruiter\"\n```\n\n## File list\n```python\n[\n    \"main.py\",\n    \"candidate_matching.py\",\n    \"dashboard.py\",\n    \"candidate_tracking.py\",\n    \"task_automation.py\",\n    \"templates/index.html\",\n    \"static/css/main.css\",\n    \"requirements.txt\"\n]\n```\n\n## Data structures and interface definitions\n```mermaid\nclassDiagram\n    class Main{\n        +Flask app\n        +run()\n    }\n    class CandidateMatching{\n        +Spacy nlp\n        +match(candidate: str, job_description: str): float\n    }\n    class Dashboard{\n        +Plotly plot\n        +generate_dashboard(data: dict): str\n    }\n    class CandidateTracking{\n        +SQLite3 db\n        +add_candidate(candidate: dict)\n        +update_candidate(candidate: dict)\n        +delete_candidate(candidate_id: str)\n        +get_candidate(candidate_id: str): dict\n    }\n    class TaskAutomation{\n        +Celery task\n        +automate_task(task: str)\n    }\n    Main -- CandidateMatching\n    Main -- Dashboard\n    Main -- CandidateTracking\n    Main -- TaskAutomation\n```\n\n## Program call flow\n```mermaid\nsequenceDiagram\n    participant M as Main\n    participant CM as CandidateMatching\n    participant D as Dashboard\n    participant CT as CandidateTracking\n    participant TA as TaskAutomation\n    M->>CM: match(candidate, job_description)\n    CM-->>M: match_score\n    M->>D: generate_dashboard(data)\n    D-->>M: dashboard_html\n    M->>CT: add_candidate(candidate)\n    CT-->>M: candidate_id\n    M->>TA: automate_task(task)\n    TA-->>M: task_status\n```\n\n## Anything UNCLEAR\nThe requirement is clear to me."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "\n",
            "Content of /content/metagpt/workspace/ai_recruiter/docs/prd.md:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Original Requirements\nThe boss wants us to build a tool for recruiters to leverage AI in their day-to-day operations.\n\n## Product Goals\n```python\n[\n    \"Create a tool that integrates AI to streamline the recruitment process\",\n    \"Improve efficiency and accuracy in candidate selection\",\n    \"Provide insightful data analytics to aid in decision-making\"\n]\n```\n\n## User Stories\n```python\n[\n    \"As a recruiter, I want to easily sift through a large number of applications, so I can shortlist candidates more efficiently\",\n    \"As a recruiter, I want to leverage AI to identify the best-fit candidates, so I can reduce the time spent on manual screening\",\n    \"As a recruiter, I want to have a dashboard that displays insightful analytics, so I can make data-driven decisions\",\n    \"As a recruiter, I want to track the progress of each candidate, so I can manage the recruitment pipeline effectively\",\n    \"As a recruiter, I want to automate repetitive tasks, so I can focus on more strategic aspects of recruitment\"\n]\n```\n\n## Competitive Analysis\n```python\n[\n    \"LinkedIn Recruiter: Offers a comprehensive suite of tools but lacks advanced AI capabilities\",\n    \"Zoho Recruit: Provides AI-powered candidate matching but lacks robust data analytics\",\n    \"Workable: Features a strong AI matching system but the user interface can be improved\",\n    \"Jobvite: Offers a good balance of AI and analytics but can be expensive for small businesses\",\n    \"Greenhouse: Known for its user-friendly interface but lacks advanced AI features\",\n    \"Lever: Provides robust analytics but the AI capabilities are not as strong\",\n    \"Breezy HR: Offers a good balance of AI and analytics but the user interface can be improved\"\n]\n```\n\n## Competitive Quadrant Chart\n```mermaid\nquadrantChart\n    title AI Capabilities and Data Analytics of Competitors\n    x-axis Low AI Capabilities --> High AI Capabilities\n    y-axis Low Data Analytics --> High Data Analytics\n    quadrant-1 We should expand\n    quadrant-2 Need to promote\n    quadrant-3 Re-evaluate\n    quadrant-4 May be improved\n    \"LinkedIn Recruiter\": [0.4, 0.6]\n    \"Zoho Recruit\": [0.7, 0.4]\n    \"Workable\": [0.6, 0.5]\n    \"Jobvite\": [0.5, 0.5]\n    \"Greenhouse\": [0.4, 0.7]\n    \"Lever\": [0.5, 0.6]\n    \"Breezy HR\": [0.6, 0.4]\n    \"Our Target Product\": [0.8, 0.8]\n```\n\n## Requirement Analysis\nThe product should be a web-based tool that integrates AI to automate and streamline the recruitment process. It should offer features such as AI-powered candidate matching, a dashboard for data analytics, candidate tracking, and task automation.\n\n## Requirement Pool\n```python\n[\n    (\"AI-powered candidate matching\", \"P0\"),\n    (\"Data analytics dashboard\", \"P0\"),\n    (\"Candidate tracking system\", \"P1\"),\n    (\"Task automation\", \"P1\"),\n    (\"User-friendly interface\", \"P2\")\n]\n```\n\n## UI Design draft\nThe main elements of the UI should include a navigation bar, a dashboard, a candidate list, and a task list. The dashboard should display key analytics in a visually appealing manner using charts and graphs. The candidate list should allow for easy sorting and filtering. The task list should provide a clear overview of pending tasks. The overall design should be clean and minimalist, with a focus on usability.\n\n## Anything UNCLEAR\nThere are no unclear points."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tgJE3NKQBm2t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}